{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Failed to set locale category LC_NUMERIC to en_HK.\n",
      "Warning: Failed to set locale category LC_TIME to en_HK.\n",
      "Warning: Failed to set locale category LC_COLLATE to en_HK.\n",
      "Warning: Failed to set locale category LC_MONETARY to en_HK.\n",
      "Warning: Failed to set locale category LC_MESSAGES to en_HK.\n",
      "--2020-02-17 20:23:43--  http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
      "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
      "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 978202 (955K) [application/zip]\n",
      "Saving to: ‘ml-latest-small.zip’\n",
      "\n",
      "ml-latest-small.zip 100%[===================>] 955.28K   765KB/s    in 1.2s    \n",
      "\n",
      "2020-02-17 20:23:45 (765 KB/s) - ‘ml-latest-small.zip’ saved [978202/978202]\n",
      "\n",
      "Archive:  ml-latest-small.zip\n",
      "   creating: ml-latest-small/\n",
      "  inflating: ml-latest-small/links.csv  \n",
      "  inflating: ml-latest-small/tags.csv  \n",
      "  inflating: ml-latest-small/ratings.csv  \n",
      "  inflating: ml-latest-small/README.txt  \n",
      "  inflating: ml-latest-small/movies.csv  \n"
     ]
    }
   ],
   "source": [
    "# download and extract movielens dataset\n",
    "!wget http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
    "!unzip ml-latest-small.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>imdbId</th>\n",
       "      <th>tmdbId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>114709</td>\n",
       "      <td>862.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113497</td>\n",
       "      <td>8844.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>113228</td>\n",
       "      <td>15602.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>114885</td>\n",
       "      <td>31357.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>113041</td>\n",
       "      <td>11862.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId  imdbId   tmdbId\n",
       "0        1  114709    862.0\n",
       "1        2  113497   8844.0\n",
       "2        3  113228  15602.0\n",
       "3        4  114885  31357.0\n",
       "4        5  113041  11862.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>tag</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>60756</td>\n",
       "      <td>funny</td>\n",
       "      <td>1445714994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>60756</td>\n",
       "      <td>Highly quotable</td>\n",
       "      <td>1445714996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>60756</td>\n",
       "      <td>will ferrell</td>\n",
       "      <td>1445714992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>89774</td>\n",
       "      <td>Boxing story</td>\n",
       "      <td>1445715207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>89774</td>\n",
       "      <td>MMA</td>\n",
       "      <td>1445715200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId              tag   timestamp\n",
       "0       2    60756            funny  1445714994\n",
       "1       2    60756  Highly quotable  1445714996\n",
       "2       2    60756     will ferrell  1445714992\n",
       "3       2    89774     Boxing story  1445715207\n",
       "4       2    89774              MMA  1445715200"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data inspection and preprocessing\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "download_dir = './ml-latest-small'\n",
    "links = pd.read_csv(download_dir + '/links.csv')\n",
    "display(links.head())\n",
    "tag = pd.read_csv(download_dir + '/tags.csv')\n",
    "display(tag.head())\n",
    "ratings = pd.read_csv(download_dir + '/ratings.csv')\n",
    "display(ratings.head())\n",
    "movies = pd.read_csv(download_dir + '/movies.csv')\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this dataset, the movies are provided genres, and the time of ratings are given. Both are useful information, however the former are not usually given in a collaborative filtering setting. The latter can tell us how the user profile has changed over years, this will be used in part II of this experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>Heat (1995)</td>\n",
       "      <td>Action|Crime|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>Seven (a.k.a. Se7en) (1995)</td>\n",
       "      <td>Mystery|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>Usual Suspects, The (1995)</td>\n",
       "      <td>Crime|Mystery|Thriller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp                        title  \\\n",
       "0       1        1     4.0       2000             Toy Story (1995)   \n",
       "1       1        3     4.0       2000      Grumpier Old Men (1995)   \n",
       "2       1        6     4.0       2000                  Heat (1995)   \n",
       "3       1       47     5.0       2000  Seven (a.k.a. Se7en) (1995)   \n",
       "4       1       50     5.0       2000   Usual Suspects, The (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                               Comedy|Romance  \n",
       "2                        Action|Crime|Thriller  \n",
       "3                             Mystery|Thriller  \n",
       "4                       Crime|Mystery|Thriller  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# left join genres onto ratings table\n",
    "df = ratings.join(movies.set_index('movieId'), on='movieId')\n",
    "# turn timestamp from seconds to year\n",
    "change_to_year = lambda x: pd.Timestamp(x, unit='s').year\n",
    "df.timestamp = df.timestamp.apply(change_to_year)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to numerically encode features and create mapping for them\n",
    "userId_map = {}\n",
    "userId_set = set(df.userId.tolist())\n",
    "for i, userId in enumerate(userId_set):\n",
    "    userId_map[userId] = i\n",
    "\n",
    "movieId_map = {}\n",
    "movieId_set = set(df.movieId.tolist())\n",
    "for i, movieId in enumerate(movieId_set):\n",
    "    movieId_map[movieId] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I: Generalized matrix factorization (a.k.a low rank k matrix approximation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "minimize (p, q, $b_i$, $b_u$) $$\\sum_{(u, i)\\in K} (r_{ui} - q_i^T.p_u - \\mu_i - b_i - b_u)^2 + \\lambda(|q_i|^2 + |p_u|^2 + |b_i|^2 + |b_u|^2)$$\n",
    "\n",
    "where $q_i$, $p_u$ are the feature vectors or embeddings for movie i and user u respectively, K is the set that the rating is made for movie i from user u, $b_i$ and $b_u$ are the bias units and $\\lambda$ is our regularization hyperparameter, subtracting the $\\mu$ (mean rating for movie i) is to make sure that when doing gradient descent, due to regularization, the model will not tend to predict the rating to be 0, instead, it will tend to be the mean value for movie i.\n",
    "\n",
    "For more detail, refer to the <a href='http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.173.2797&rep=rep1&type=pdf'>original paper</a> by Yunhong Zhou. et al in 2008."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "n_movies = len(df.movieId.unique())\n",
    "n_users = len(df.userId.unique())\n",
    "hidden_d = 100\n",
    "\n",
    "# prepare the mean rating vector for movies\n",
    "mu = df.groupby(['movieId']).mean()['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numercially encode movieId, userId and create mapping\n",
    "movie_map = set(df.movieId.tolist())\n",
    "movie_map = {movie:i for i, movie in enumerate(movie_map)}\n",
    "\n",
    "user_map = set(df.userId.tolist())\n",
    "user_map = {user:i for i, user in enumerate(user_map)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = mu.reset_index()\n",
    "mu.movieId = mu.movieId.apply(lambda x: movie_map[x])\n",
    "mu = mu.sort_values(by=['movieId'])\n",
    "mu = torch.Tensor(mu.rating.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define neural network architechture in pytorch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class classicalNet(nn.Module):\n",
    "    def __init__(self, n_movies, n_users, hidden_d, mu):\n",
    "        super(classicalNet, self).__init__()\n",
    "        self.W1 = torch.rand((hidden_d, n_movies), requires_grad=True)\n",
    "        self.W2 = torch.rand((hidden_d, n_users), requires_grad=True)\n",
    "        self.b1 = torch.rand(n_movies, requires_grad=True)\n",
    "        self.b2 = torch.rand(n_users, requires_grad=True)\n",
    "        # dimension: n_movies\n",
    "        self.mu = mu\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        \"x1: n_movies by batch_dimension\"\n",
    "        \"x2: n_users by batch_dimension\"\n",
    "        \n",
    "        # get movie no.\n",
    "        i = torch.argmax(x1, dim=0)\n",
    "        # get user no.\n",
    "        u = torch.argmax(x2, dim=0)\n",
    "        \n",
    "        x1 = torch.mm(self.W1, x1)\n",
    "        x1 = x1.t()\n",
    "        x2 = torch.mm(self.W2, x2)\n",
    "        \n",
    "        x = torch.zeros(x2.size(1))\n",
    "        for k in range(x2.size(1)):\n",
    "            x[k] += torch.dot(x1[k], x2[:, k]) + self.mu[i[k]] + self.b1[i[k]] + self.b2[u[k]]\n",
    "            \n",
    "        # below is a bad example by rewrapping a tensor, this break the computation graph and results in grad==None\n",
    "        \n",
    "#         x = torch.tensor([torch.dot(x1[k], x2[:, k]) for k in range(x2.size(1))], requires_grad=True)\n",
    "        \n",
    "#         x = x + torch.tensor([self.mu[i[k]] for k in range(x2.size(1))]) \\\n",
    "#                 + torch.tensor([self.b1[i[k]] for k in range(x2.size(1))]) \\\n",
    "#                 + torch.tensor([self.b2[u[k]] for k in range(x2.size(1))])\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def rmseloss(self, pred, r):\n",
    "        \"pred, ratings: batch_dimension\"\n",
    "\n",
    "        loss = torch.tensor(0.)\n",
    "        count = 0\n",
    "        \n",
    "        # implement MSE loss assuming not all ratings are present in r\n",
    "        for k in range(r.size(0)):\n",
    "            if ~torch.isnan(r[k]):\n",
    "                loss += (pred[k] - r[k])**2\n",
    "                count += 1\n",
    "        \n",
    "        # regularization with lambda=0.0001\n",
    "        loss += 0.0001 * ((self.W1 * self.W1).sum() + (self.W2 * self.W2).sum() \\\n",
    "                                            + (self.b1 * self.b1).sum() + (self.b2 * self.b2).sum())\n",
    "        loss = loss / count\n",
    "        return loss**0.5\n",
    "\n",
    "classical_net = classicalNet(n_movies, n_users, hidden_d, mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam([classical_net.W1, classical_net.W2, classical_net.b1, classical_net.b2], lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare train, validation, test sets\n",
    "X = df.iloc[:, 0:2]\n",
    "y = df.iloc[:, 2]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 70% train, 21% validation, 9% test\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_validation, y_validation, test_size=0.3, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate tensor for pytorch model's input and output for SGD\n",
    "def batch_generator(X, y, batch_size):\n",
    "    for i in range(X.shape[0]//batch_size):\n",
    "        batch_input = X.iloc[i*batch_size: i*batch_size + batch_size]\n",
    "        batch_output = y.iloc[i*batch_size: i*batch_size + batch_size]\n",
    "\n",
    "        movie_input = []\n",
    "        user_input = []\n",
    "        rating_output = []\n",
    "        \n",
    "        for _, input_ in batch_input.iterrows():\n",
    "            user_vector = np.zeros(len(user_map))\n",
    "            user_vector[user_map[input_.userId]] = 1.\n",
    "            user_input.append(user_vector)\n",
    "                    \n",
    "            movie_vector = np.zeros(len(movie_map))\n",
    "            movie_vector[movie_map[input_.movieId]] = 1.\n",
    "            movie_input.append(movie_vector)\n",
    "\n",
    "        for _, output in batch_output.iteritems():\n",
    "            rating_output.append(output)\n",
    "        \n",
    "        # make sure torch.float for backprop\n",
    "        movie_input = torch.tensor(movie_input, dtype=torch.float32)\n",
    "        user_input = torch.tensor(user_input, dtype=torch.float32)\n",
    "        # for tensor of dimension, n_movies by batch_no\n",
    "        movie_input = movie_input.t()\n",
    "        user_input = user_input.t()\n",
    "        rating_output = torch.tensor(rating_output, dtype=torch.float32)\n",
    "\n",
    "        yield movie_input, user_input, rating_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 5000\n",
    "X_validation_sample = X_validation.iloc[:sample_size]\n",
    "y_validation_sample = y_validation.iloc[:sample_size]\n",
    "\n",
    "X_training_sample = X_train.iloc[:sample_size]\n",
    "y_training_sample = y_train.iloc[:sample_size]\n",
    "\n",
    "def loss_check(model, X, y):\n",
    "    with torch.no_grad():\n",
    "        X_movie, X_user, y_rating = list(batch_generator(X, y, len(X)))[0]\n",
    "        prediction = model(X_movie, X_user)\n",
    "        return model.rmseloss(prediction, y_rating).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None False\n",
      "tensor([[9.2125e-04, 5.3908e-04, 2.9790e-05,  ..., 3.5250e-10, 1.3638e-09,\n",
      "         1.8333e-09],\n",
      "        [6.1690e-04, 7.7889e-04, 4.2534e-04,  ..., 1.9517e-09, 3.0922e-09,\n",
      "         1.6568e-09],\n",
      "        [1.0792e-03, 8.0708e-04, 3.8648e-04,  ..., 2.0125e-09, 2.0011e-09,\n",
      "         1.6532e-11],\n",
      "        ...,\n",
      "        [7.7293e-04, 5.7279e-04, 5.3417e-04,  ..., 1.7969e-09, 2.8181e-09,\n",
      "         2.5089e-09],\n",
      "        [1.4738e-03, 1.5810e-04, 9.8194e-05,  ..., 9.0100e-10, 9.3269e-11,\n",
      "         7.9214e-10],\n",
      "        [1.5004e-03, 7.1684e-04, 5.9747e-04,  ..., 1.3143e-09, 9.7395e-10,\n",
      "         2.3794e-09]]) True\n",
      "tensor([[1.4209e-03, 3.2698e-09, 1.7994e-09,  ..., 2.8940e-03, 9.9192e-10,\n",
      "         4.3054e-03],\n",
      "        [1.9449e-03, 2.2035e-09, 4.3314e-10,  ..., 3.2645e-03, 1.7121e-09,\n",
      "         6.5289e-03],\n",
      "        [1.5263e-03, 1.0992e-09, 2.9595e-09,  ..., 3.9215e-03, 1.8328e-09,\n",
      "         5.1936e-03],\n",
      "        ...,\n",
      "        [2.6547e-03, 7.6003e-10, 2.0156e-09,  ..., 2.9230e-03, 1.3724e-09,\n",
      "         5.2341e-03],\n",
      "        [1.5236e-03, 6.6227e-10, 2.8443e-09,  ..., 3.6362e-03, 2.2236e-09,\n",
      "         6.4152e-03],\n",
      "        [2.0894e-03, 2.5943e-09, 2.6594e-09,  ..., 3.7500e-03, 3.3333e-09,\n",
      "         6.8322e-03]]) True\n",
      "tensor([2.6668e-03, 9.3845e-04, 1.0458e-03,  ..., 3.1182e-09, 2.1369e-09,\n",
      "        2.6399e-09]) True\n",
      "tensor([4.0194e-03, 1.0078e-09, 1.3189e-09, 2.8405e-03, 3.9208e-11, 4.8338e-03,\n",
      "        1.0134e-03, 1.0711e-03, 1.9282e-03, 1.0136e-03, 1.3621e-09, 8.5602e-04,\n",
      "        2.6461e-09, 1.7640e-03, 2.0774e-03, 1.9692e-03, 2.0854e-03, 1.0213e-03,\n",
      "        7.2960e-03, 1.9258e-03, 2.8332e-03, 1.9163e-09, 8.6219e-04, 9.6416e-04,\n",
      "        1.0560e-03, 1.8967e-09, 9.5228e-04, 1.0437e-02, 1.7967e-03, 2.5503e-09,\n",
      "        3.0227e-09, 9.1053e-04, 3.9426e-03, 8.6984e-04, 9.7118e-10, 3.6804e-09,\n",
      "        3.0756e-09, 1.0849e-03, 4.9145e-03, 1.9602e-09, 1.1628e-03, 5.0029e-03,\n",
      "        2.5426e-03, 1.0458e-03, 4.0120e-03, 1.1182e-09, 2.2656e-09, 1.0538e-03,\n",
      "        1.0662e-03, 4.7857e-10, 3.7597e-03, 9.6950e-04, 8.8513e-04, 2.4970e-10,\n",
      "        2.3928e-09, 5.7595e-11, 2.0534e-03, 7.7376e-10, 8.8426e-04, 9.3282e-04,\n",
      "        3.6381e-09, 4.0417e-03, 5.5001e-03, 3.8357e-03, 5.4739e-10, 9.8471e-04,\n",
      "        7.9277e-04, 1.4710e-02, 3.4948e-09, 7.1123e-10, 2.0980e-09, 2.9106e-09,\n",
      "        1.9626e-03, 2.9165e-03, 2.9261e-09, 9.6710e-04, 3.0685e-09, 3.4485e-09,\n",
      "        1.6559e-03, 8.6787e-04, 4.0276e-10, 1.7566e-03, 9.7685e-04, 1.3358e-09,\n",
      "        2.2147e-09, 7.6686e-04, 3.3912e-09, 8.8865e-04, 3.2744e-03, 1.9742e-03,\n",
      "        5.7529e-03, 4.4893e-10, 8.4716e-04, 3.0316e-03, 3.7658e-03, 9.7617e-04,\n",
      "        3.1374e-09, 1.9387e-03, 8.3627e-04, 9.2692e-04, 2.8945e-11, 3.3670e-09,\n",
      "        5.2468e-03, 9.6092e-04, 9.9265e-04, 1.0602e-03, 9.4587e-10, 2.8504e-09,\n",
      "        2.5388e-09, 3.0858e-09, 9.2972e-04, 9.0012e-04, 2.4397e-09, 1.1135e-03,\n",
      "        1.5660e-03, 1.1287e-03, 2.9687e-03, 8.6843e-10, 1.5464e-09, 1.1080e-03,\n",
      "        2.8947e-03, 1.6589e-03, 1.7568e-03, 3.2336e-09, 5.3025e-03, 9.8811e-04,\n",
      "        1.2064e-09, 9.6606e-04, 2.1478e-03, 1.8574e-03, 1.9455e-03, 1.1356e-03,\n",
      "        1.0474e-09, 2.8631e-09, 1.0296e-03, 9.6538e-04, 8.7179e-04, 7.0121e-10,\n",
      "        2.0003e-03, 7.7416e-03, 9.3558e-04, 9.7651e-10, 9.6065e-04, 8.7880e-04,\n",
      "        1.8313e-09, 2.5602e-09, 1.5298e-09, 1.5231e-09, 1.0601e-03, 7.5655e-10,\n",
      "        2.7908e-09, 8.0566e-11, 3.0167e-03, 7.6344e-10, 1.2558e-03, 1.6311e-03,\n",
      "        7.1572e-10, 7.1610e-10, 1.0776e-03, 3.8326e-03, 2.2901e-09, 3.4809e-09,\n",
      "        9.5191e-04, 9.1761e-04, 9.4180e-04, 2.9960e-03, 3.1437e-03, 8.2846e-04,\n",
      "        3.7709e-03, 1.0133e-03, 1.1422e-10, 2.8127e-09, 8.9892e-10, 1.9106e-03,\n",
      "        9.4807e-04, 1.1684e-09, 1.1087e-02, 3.5703e-09, 9.2669e-04, 1.3580e-09,\n",
      "        1.7160e-09, 6.0945e-03, 8.8225e-04, 2.4650e-09, 3.6396e-09, 4.9497e-03,\n",
      "        3.0516e-03, 1.1992e-03, 9.8967e-10, 9.1429e-04, 1.6357e-09, 2.5779e-09,\n",
      "        9.0730e-04, 2.8647e-09, 5.2513e-03, 1.2407e-09, 3.0929e-03, 2.0321e-03,\n",
      "        4.9706e-03, 2.0719e-03, 3.5870e-09, 5.0425e-03, 9.4911e-04, 3.4378e-09,\n",
      "        1.6192e-09, 8.7826e-04, 1.9189e-09, 7.7126e-10, 1.0051e-09, 1.7578e-03,\n",
      "        1.7006e-10, 4.7536e-03, 9.0848e-04, 3.6078e-09, 7.3039e-10, 2.1086e-03,\n",
      "        5.7734e-03, 3.5681e-09, 1.2408e-02, 4.0380e-03, 3.2431e-03, 5.1378e-03,\n",
      "        9.4475e-04, 1.3942e-09, 5.3655e-10, 2.7905e-03, 1.9716e-03, 1.3692e-09,\n",
      "        2.1841e-09, 4.8789e-03, 1.0196e-03, 7.9219e-03, 1.4757e-09, 1.7512e-03,\n",
      "        9.4898e-04, 5.2348e-10, 1.9429e-03, 2.9909e-09, 4.4883e-03, 9.2011e-04,\n",
      "        3.1674e-09, 2.0584e-09, 1.0391e-03, 1.8211e-03, 9.5673e-04, 9.6243e-04,\n",
      "        1.0090e-03, 3.0242e-09, 9.2659e-03, 1.3150e-09, 1.0794e-09, 8.6188e-04,\n",
      "        1.4369e-09, 8.4573e-04, 1.0365e-03, 3.6624e-09, 2.4517e-09, 9.4110e-04,\n",
      "        9.8077e-04, 1.7726e-03, 1.7501e-10, 9.5247e-04, 1.8700e-03, 1.9069e-03,\n",
      "        2.9569e-03, 3.0851e-03, 3.3781e-09, 1.8627e-03, 1.2610e-09, 3.2559e-09,\n",
      "        1.6762e-09, 1.9184e-09, 9.9887e-04, 3.0847e-03, 5.4923e-03, 1.3600e-09,\n",
      "        3.3248e-09, 3.6574e-09, 3.2038e-03, 1.6437e-03, 1.8952e-09, 2.0552e-03,\n",
      "        2.6753e-09, 1.3129e-09, 9.2527e-04, 1.9190e-03, 1.0989e-03, 1.4074e-02,\n",
      "        1.5798e-09, 2.0036e-03, 1.0862e-03, 4.7289e-03, 9.3856e-10, 2.0700e-03,\n",
      "        3.4307e-09, 8.0573e-10, 3.2922e-09, 5.5056e-03, 6.1502e-10, 3.2731e-09,\n",
      "        3.5329e-09, 2.0448e-03, 9.8048e-10, 2.7310e-03, 4.4531e-03, 1.8688e-03,\n",
      "        1.5000e-02, 1.0595e-03, 1.0868e-03, 9.4644e-04, 1.7437e-09, 4.1616e-03,\n",
      "        3.5434e-03, 2.7929e-03, 5.6053e-10, 3.1550e-09, 2.0681e-03, 1.0775e-02,\n",
      "        1.4563e-09, 9.5575e-10, 8.7581e-04, 2.0226e-03, 1.6730e-03, 1.3164e-09,\n",
      "        6.4102e-03, 2.7983e-03, 1.4805e-09, 6.4417e-03, 5.0028e-10, 1.6773e-03,\n",
      "        1.8536e-03, 8.2336e-03, 2.8097e-09, 2.0521e-03, 2.9480e-09, 1.9267e-11,\n",
      "        2.6651e-09, 1.0214e-03, 4.7708e-03, 2.5349e-09, 2.8867e-09, 1.8993e-03,\n",
      "        9.0783e-10, 1.7075e-03, 2.3031e-09, 1.9279e-09, 9.0141e-04, 1.1597e-03,\n",
      "        3.6870e-09, 4.2866e-10, 4.6209e-10, 2.7271e-03, 2.5466e-09, 9.9962e-04,\n",
      "        5.9537e-10, 2.6380e-03, 2.2896e-03, 2.2686e-09, 1.3972e-09, 3.1716e-09,\n",
      "        1.0120e-03, 8.7205e-04, 2.8876e-09, 5.5122e-10, 1.2745e-03, 9.5336e-04,\n",
      "        9.3198e-04, 5.8055e-03, 8.8027e-04, 1.9406e-09, 3.4290e-09, 1.8784e-03,\n",
      "        3.3341e-09, 1.6978e-09, 1.7853e-09, 3.0614e-03, 3.0042e-10, 6.6197e-10,\n",
      "        1.6144e-09, 1.4301e-02, 7.3323e-03, 9.4966e-04, 8.6876e-04, 8.7504e-04,\n",
      "        4.2072e-03, 9.8213e-04, 1.0409e-02, 2.6423e-09, 1.3118e-09, 2.0504e-03,\n",
      "        2.8372e-03, 1.0596e-03, 8.4114e-04, 7.4138e-10, 1.5189e-09, 1.2643e-09,\n",
      "        3.4755e-09, 9.5002e-04, 8.5076e-04, 2.1755e-09, 8.5881e-04, 2.0999e-03,\n",
      "        1.3399e-09, 5.6526e-10, 1.9034e-03, 4.7455e-10, 1.6088e-09, 5.6701e-12,\n",
      "        2.1422e-03, 2.8269e-09, 9.7021e-04, 1.4520e-09, 1.0295e-03, 2.1697e-02,\n",
      "        3.0937e-09, 1.1596e-03, 1.3937e-09, 9.6802e-04, 9.9967e-04, 3.7927e-03,\n",
      "        8.8733e-04, 1.0127e-03, 6.4052e-10, 3.7699e-03, 2.7579e-03, 2.0792e-03,\n",
      "        1.8999e-09, 7.9693e-04, 2.4913e-10, 1.0863e-09, 1.1402e-09, 1.1025e-03,\n",
      "        9.3514e-04, 3.7305e-03, 1.7896e-03, 2.1606e-09, 2.8174e-03, 4.1934e-03,\n",
      "        2.2524e-09, 3.1899e-09, 8.9121e-04, 3.1118e-09, 1.5486e-09, 3.2480e-10,\n",
      "        9.4799e-04, 2.3695e-09, 2.4853e-09, 2.0237e-02, 9.0437e-04, 7.8014e-10,\n",
      "        9.4167e-10, 8.7038e-04, 2.7209e-03, 2.2055e-09, 3.5705e-09, 9.7302e-04,\n",
      "        9.8860e-04, 1.8022e-03, 1.7612e-09, 1.0868e-03, 8.2483e-10, 4.5018e-03,\n",
      "        1.0187e-03, 3.4720e-09, 1.0340e-03, 9.6711e-04, 2.2945e-10, 7.9080e-04,\n",
      "        2.2549e-03, 3.0678e-09, 2.1039e-03, 3.7253e-09, 6.3498e-10, 2.0032e-02,\n",
      "        3.7640e-03, 1.0601e-03, 6.0030e-03, 3.2014e-09, 9.9779e-04, 8.5458e-03,\n",
      "        3.2303e-09, 1.9582e-03, 5.3683e-03, 2.9063e-03, 3.4483e-09, 9.4505e-04,\n",
      "        9.6297e-04, 9.5176e-04, 4.9827e-03, 9.0871e-04, 1.9450e-03, 9.3259e-04,\n",
      "        9.2973e-10, 6.2096e-10, 1.7789e-03, 3.3938e-10, 9.6331e-04, 1.7511e-09,\n",
      "        6.5905e-11, 1.8503e-03, 2.0300e-03, 2.1327e-03, 5.1581e-10, 3.3476e-09,\n",
      "        3.4586e-09, 1.0074e-03, 9.5070e-04, 1.0304e-03, 2.8835e-03, 1.7337e-03,\n",
      "        1.1399e-03, 2.7736e-09, 2.7292e-09, 5.7114e-03, 1.6619e-09, 3.6089e-09,\n",
      "        3.2125e-03, 1.8531e-10, 3.0997e-09, 1.9040e-03, 2.4036e-09, 9.9219e-04,\n",
      "        1.5053e-09, 3.9134e-03, 6.0040e-03, 2.0456e-03, 1.1656e-03, 8.4683e-04,\n",
      "        3.7096e-03, 1.9991e-09, 1.5993e-09, 2.5398e-09, 7.6024e-10, 4.8191e-03,\n",
      "        3.6023e-09, 8.8145e-04, 2.2955e-11, 8.7663e-04, 2.5269e-09, 2.3917e-09,\n",
      "        3.5211e-09, 3.5950e-09, 8.9726e-04, 1.4617e-09, 1.3326e-09, 1.8593e-09,\n",
      "        1.8745e-09, 1.5008e-09, 1.5950e-10, 1.9639e-09, 1.0458e-09, 5.8305e-03,\n",
      "        9.0411e-04, 2.9999e-09, 5.1611e-03, 4.7474e-10, 1.1461e-09, 8.8296e-04,\n",
      "        9.2052e-10, 3.1179e-03, 6.8787e-03, 3.6536e-03, 1.1330e-03, 8.5025e-10,\n",
      "        1.1881e-09, 2.6398e-10, 4.8454e-03, 2.9706e-09, 7.6979e-10, 1.3869e-09,\n",
      "        9.6948e-04, 2.8153e-03, 4.1028e-03, 3.5176e-09, 9.4374e-04, 2.9976e-09,\n",
      "        9.7969e-04, 3.0341e-09, 9.8563e-04, 1.8162e-03, 2.4731e-10, 8.4506e-04,\n",
      "        2.7629e-09, 8.4473e-10, 2.1855e-09, 4.9082e-03, 3.1154e-03, 9.5043e-04,\n",
      "        2.6669e-09, 6.0081e-03, 3.5812e-09, 8.9776e-04, 9.4254e-04, 1.8257e-03,\n",
      "        2.5591e-09, 3.5343e-03, 4.3614e-03, 2.8066e-10, 2.1522e-02, 8.6528e-03,\n",
      "        1.7531e-03, 9.1987e-04, 4.7683e-03, 1.2511e-09, 5.9770e-03, 1.5684e-02,\n",
      "        9.7156e-04, 6.9320e-03, 1.2423e-09, 1.1437e-02]) True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 30] average_loss per batch: 25.320961825052898\n",
      "[1, 60] average_loss per batch: 23.435988171895346\n",
      "training_loss: 22.06778907775879\n",
      "validation_loss: 22.04291534423828\n",
      "[2, 30] average_loss per batch: 21.251647504170737\n",
      "[2, 60] average_loss per batch: 19.557798767089842\n",
      "training_loss: 18.401865005493164\n",
      "validation_loss: 18.386045455932617\n",
      "[3, 30] average_loss per batch: 17.671925226847332\n",
      "[3, 60] average_loss per batch: 16.16515153249105\n",
      "training_loss: 15.184741973876953\n",
      "validation_loss: 15.18737506866455\n",
      "[4, 30] average_loss per batch: 14.536856619517009\n",
      "[4, 60] average_loss per batch: 13.205230681101481\n",
      "training_loss: 12.375256538391113\n",
      "validation_loss: 12.399706840515137\n",
      "[5, 30] average_loss per batch: 11.802329794565837\n",
      "[5, 60] average_loss per batch: 10.630350462595622\n",
      "training_loss: 9.93094539642334\n",
      "validation_loss: 9.980087280273438\n",
      "[6, 30] average_loss per batch: 9.426313050587972\n",
      "[6, 60] average_loss per batch: 8.400098609924317\n",
      "training_loss: 7.816278457641602\n",
      "validation_loss: 7.893249988555908\n",
      "[7, 30] average_loss per batch: 7.375430631637573\n",
      "[7, 60] average_loss per batch: 6.486124674479167\n",
      "training_loss: 6.008713722229004\n",
      "validation_loss: 6.116292953491211\n",
      "[8, 30] average_loss per batch: 5.631020959218343\n",
      "[8, 60] average_loss per batch: 4.878307104110718\n",
      "training_loss: 4.504965782165527\n",
      "validation_loss: 4.643610000610352\n",
      "[9, 30] average_loss per batch: 4.194884665807089\n",
      "[9, 60] average_loss per batch: 3.5887722333272296\n",
      "training_loss: 3.3214364051818848\n",
      "validation_loss: 3.4873995780944824\n",
      "[10, 30] average_loss per batch: 3.0861139853795367\n",
      "[10, 60] average_loss per batch: 2.6383878628412885\n",
      "training_loss: 2.470427989959717\n",
      "validation_loss: 2.6579010486602783\n",
      "[11, 30] average_loss per batch: 2.309306351343791\n",
      "[11, 60] average_loss per batch: 2.0094894727071124\n",
      "training_loss: 1.9128087759017944\n",
      "validation_loss: 2.120878219604492\n",
      "[12, 30] average_loss per batch: 1.8100017348925272\n",
      "[12, 60] average_loss per batch: 1.6195173223813375\n",
      "training_loss: 1.560646414756775\n",
      "validation_loss: 1.7930400371551514\n",
      "[13, 30] average_loss per batch: 1.4957810560862224\n",
      "[13, 60] average_loss per batch: 1.3743088960647583\n",
      "training_loss: 1.3334746360778809\n",
      "validation_loss: 1.5925102233886719\n",
      "[14, 30] average_loss per batch: 1.2919657468795775\n",
      "[14, 60] average_loss per batch: 1.2114759922027587\n",
      "training_loss: 1.1800256967544556\n",
      "validation_loss: 1.4663153886795044\n",
      "[15, 30] average_loss per batch: 1.1531143625577291\n",
      "[15, 60] average_loss per batch: 1.0962299307187398\n",
      "training_loss: 1.0702435970306396\n",
      "validation_loss: 1.384260654449463\n",
      "[16, 30] average_loss per batch: 1.0527070899804434\n",
      "[16, 60] average_loss per batch: 1.0091999391714732\n",
      "training_loss: 0.9865884184837341\n",
      "validation_loss: 1.3290568590164185\n",
      "[17, 30] average_loss per batch: 0.9752484500408173\n",
      "[17, 60] average_loss per batch: 0.9394118924935658\n",
      "training_loss: 0.918914794921875\n",
      "validation_loss: 1.290629267692566\n",
      "[18, 30] average_loss per batch: 0.9118260721365611\n"
     ]
    }
   ],
   "source": [
    "def training(n_epoch):\n",
    "    # loop over the dataset multiple times\n",
    "    batch_size = 1024\n",
    "    validation_history = []\n",
    "    training_history = []\n",
    "    patience = 3\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "\n",
    "        running_loss = 0.0\n",
    "        batch_no = 0\n",
    "        for movie_input, user_input, rating in batch_generator(X_train, y_train, batch_size):\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = classical_net(movie_input, user_input)\n",
    "            loss = classical_net.rmseloss(outputs, rating)\n",
    "            loss.backward()\n",
    "            \n",
    "            # check for normal behavior of batch gradient descent\n",
    "            # only leaf node get grad, in typical nn, all parameters are leaf nodes\n",
    "            if batch_no == 0 and epoch == 0:    \n",
    "                print(loss.grad, loss.is_leaf)\n",
    "                print(classical_net.W1.grad, classical_net.W1.is_leaf)\n",
    "                print(classical_net.W2.grad, classical_net.W2.is_leaf)\n",
    "                print(classical_net.b1.grad, classical_net.b1.is_leaf)\n",
    "                print(classical_net.b2.grad, classical_net.b2.is_leaf)\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if batch_no % 30 == 29:\n",
    "                print('[{}, {}] average_loss per batch: {}'.format(epoch+1, batch_no+1, running_loss/30))\n",
    "                running_loss = 0.0\n",
    "\n",
    "            batch_no += 1\n",
    "\n",
    "        # check training and validation loss after every epoch\n",
    "        training_loss = loss_check(classical_net, X_training_sample, y_training_sample)\n",
    "        print('training_loss: {}'.format(training_loss))\n",
    "        training_history.append(training_loss)\n",
    "        vali_loss = loss_check(classical_net, X_validation_sample, y_validation_sample)\n",
    "        print('validation_loss: {}'.format(vali_loss))\n",
    "        validation_history.append(vali_loss)\n",
    "        \n",
    "        # check if vali loss is improving since last few epochs\n",
    "        if len(validation_history) >= patience:\n",
    "            if abs(validation_history[-1] - validation_history[-patience]) / validation_history[-patience] < 0.005:\n",
    "                print('Early stopping')\n",
    "                break\n",
    "\n",
    "    print('Finished Training')\n",
    "    return validation_history, training_history\n",
    "\n",
    "n_epoch = 30\n",
    "validation_history, training_history = training(n_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.arange(n_epoch), validation_history, color='r', label='validation')\n",
    "plt.plot(np.arange(n_epoch), training_history, color='b', label='training with lambda=0.0001')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets see how gd our model prediction's are on the test set\n",
    "test_loss = loss_check(classical_net, X_test, y_test)\n",
    "print('test_loss: {}'.format(test_loss))\n",
    "\n",
    "# demo compared to ground truth\n",
    "with torch.no_grad():\n",
    "    X_sample, y_sample = X_test[:10], y_test[:10]\n",
    "    sample_movie, sample_user, rating_truth = list(batch_generator(X_sample, y_sample, len(X_sample)))[0]\n",
    "    print('prediction rating: {}'.format(classical_net(sample_movie, sample_user).numpy()))\n",
    "    print('ground truth rating: {}'.format(rating_truth.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "PATH = './30_epochs-classical_MFnn_earlyStopping.pth'\n",
    "torch.save(classical_net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to good old SVD method using movie embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "# form our movie-user-rating matrix\n",
    "r = np.zeros((n_movies, n_users))\n",
    "for _, row in df.iterrows():\n",
    "        r[movie_map[row.movieId], user_map[row.userId]] = row.rating\n",
    "\n",
    "svd = TruncatedSVD(n_components=100, random_state=42)\n",
    "# r_reduced: (n_movies, 100)\n",
    "r_reduced = svd.fit_transform(r)\n",
    "print('explained_variance ratio for 100 components in percentage: {}'.format(sum(svd.explained_variance_ratio_)))\n",
    "\n",
    "print('SVD embeddings for 3 sample movies: {}'.format(r_reduced[:3]))\n",
    "nn_movies_embedding_matrix = classical_net.W1.numpy()\n",
    "print('NN embeddings for 3 sample movies: {}'.format(nn_movies_embedding_matrix[:, :3].T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shortcomings for generalized matrix factorization \n",
    "1. cannot incorporate other source of information for recommendation other than user, movie embeddings\n",
    "2. only dot product is used to capture user movie interations\n",
    "3. can deep network help to learn the functional form of dot product?\n",
    "\n",
    "By Xiangnan He. et al, <a href='https://arxiv.org/pdf/1708.05031.pdf'>Neural Collaborative Filtering</a> in 2017, they proposed the following architecture and claimed to have performance, in part II of this experiment, we shall explore this setup.\n",
    "<img src='./deep_cl.png' height='700px' width='500px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part II: NeuMF machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
